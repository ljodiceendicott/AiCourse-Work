{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "## SMS Spam classification\n",
    "\n",
    "This uses the [SMS Spam dataset](https://www.dropbox.com/s/373c841oqz3usei/sms-spam.csv?dl=1) ([documentation here](https://www.kaggle.com/uciml/sms-spam-collection-dataset)). \n",
    "\n",
    "The goal is to classify an unseen SMS message as spam or not spam (also called ham). We'll examine two ways of doing this: \n",
    "\n",
    "  1. extracting numerical features and train a binary classification model \n",
    "  2. using just the words themselves to create a language model of spam and non-spam, then classify the new instance based on which language model it's closer to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following imports a number of libraries that we'll need, as well as\n",
    "# configures a number of options that will make interacting with the notebook\n",
    "# a little easier.\n",
    "\n",
    "import pandas as pd    # For reading an manipulating tabular data.\n",
    "import seaborn as sns  # For making pretty plots.\n",
    "import math            # For common math operations, such as checking for NaNs.\n",
    "import matplotlib.pyplot as plt # For plotting options.\n",
    "from sklearn.model_selection import train_test_split, KFold # For train/test.\n",
    "import re # For regular expressions.\n",
    "from sklearn import metrics # For evaluation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# By default, Pandas will only show the first 20 columns of a dataframe and\n",
    "# the first 50 characters of a string. These two settings remove those\n",
    "# restrictions so that all columns and full strings are displayed.\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Here's we'll load in the dataset and create a training, development, and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data = pd.read_csv('https://www.dropbox.com/s/373c841oqz3usei/sms-spam.csv?dl=1', encoding='latin-1')\n",
    "sms_data = pd.DataFrame({'spam': sms_data.v1=='spam', 'sms': sms_data.v2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam  \\\n",
       "0  False   \n",
       "1  False   \n",
       "2  True    \n",
       "3  False   \n",
       "4  False   \n",
       "\n",
       "                                                                                                                                                           sms  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                              \n",
       "1  Ok lar... Joking wif u oni...                                                                                                                                \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3  U dun say so early hor... U c already then say...                                                                                                            \n",
       "4  Nah I don't think he goes to usf, he lives around here though                                                                                                "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifier with numeric features\n",
    "Here we'll extract a few numeric features per SMS message:\n",
    "\n",
    "  * `length_chars` (length of message in characters)\n",
    "  * `length_tokens` (length of message in tokens)\n",
    "  * `mean_token_length` (mean number of characters per token)\n",
    "  * `num_distinct_tokens` (number of distinct tokens after case normalization and punctuation removal)\n",
    "  * `num_capital_chars` (number of capitalized characters in message)\n",
    "  * `num_capital_tokens` (number of all capitalized tokens after punctuation removal)\n",
    "  \n",
    "  \n",
    "First up, we'll extract these features for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "## Add a column to sms_data called 'length_chars' and set it to the length of the \n",
    "## 'sms' column.\n",
    "NON_ALPHA = re.compile('\\W')\n",
    "sms_data['length_chars'] = sms_data['sms'].map(len)\n",
    "sms_data['length_tokens'] = sms_data['sms'].map(lambda s: len(NON_ALPHA.sub(' ', s).split()))\n",
    "sms_data['num_distinct_tokens'] = sms_data['sms'].map(lambda s: len(list(set(NON_ALPHA.sub(' ', s).split()))))\n",
    "\n",
    "## Regular expressions\n",
    "## \\w -- alpha-numeric characters ~ [a-zA-Z0-9]\n",
    "## [A-Z]\n",
    "## [A-Z]+ -- match 1 or more capital letters\n",
    "## [A-Z]* -- match 0 or more capital letters\n",
    "## ([A-Z]+) -- match and capture all sequences of 1 or more capital letters\n",
    "## (\\b[A-Z]+\\b) -- match and capture all sequences of 1 or more capital letters \n",
    "##                 that stand alone (i.e., tokens)\n",
    "CAPITAL_LETTER = re.compile('[A-Z]')\n",
    "sms_data['num_capital_chars'] = sms_data['sms'].map(\n",
    "    lambda s: len(CAPITAL_LETTER.findall(s)))\n",
    "\n",
    "## Finds the number of all caps words that are length 1 or greater.\n",
    "CAPITAL_WORD = re.compile('\\\\b[A-Z]+\\\\b')\n",
    "sms_data['num_capital_tokens'] = sms_data['sms'].map(\n",
    "    lambda s: len(CAPITAL_WORD.findall(s)))\n",
    "\n",
    "## Finds the number of all caps words that are length 2 or greater.\n",
    "CAPITAL_WORD = re.compile('\\\\b[A-Z]{2,}\\\\b')\n",
    "sms_data['num_capital_tokens'] = sms_data['sms'].map(\n",
    "    lambda s: len(CAPITAL_WORD.findall(s)))\n",
    "\n",
    "CONTAINS_FREE = re.compile('\\\\bfree\\\\b')\n",
    "sms_data['num_free'] = sms_data['sms'].map(\n",
    "    lambda s: len(CONTAINS_FREE.findall(s.lower())))\n",
    "\n",
    "NUMBERS = re.compile('\\\\d')\n",
    "sms_data['num_digits'] = sms_data['sms'].map(\n",
    "    lambda s: len(NUMBERS.findall(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>sms</th>\n",
       "      <th>length_chars</th>\n",
       "      <th>length_tokens</th>\n",
       "      <th>num_distinct_tokens</th>\n",
       "      <th>num_capital_chars</th>\n",
       "      <th>num_capital_tokens</th>\n",
       "      <th>num_free</th>\n",
       "      <th>num_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>155</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam  \\\n",
       "0  False   \n",
       "1  False   \n",
       "2  True    \n",
       "3  False   \n",
       "4  False   \n",
       "\n",
       "                                                                                                                                                           sms  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                               \n",
       "1  Ok lar... Joking wif u oni...                                                                                                                                 \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
       "3  U dun say so early hor... U c already then say...                                                                                                             \n",
       "4  Nah I don't think he goes to usf, he lives around here though                                                                                                 \n",
       "\n",
       "   length_chars  length_tokens  num_distinct_tokens  num_capital_chars  \\\n",
       "0  111           20             20                   3                   \n",
       "1  29            6              6                    2                   \n",
       "2  155           33             28                   10                  \n",
       "3  49            11             9                    2                   \n",
       "4  61            14             13                   2                   \n",
       "\n",
       "   num_capital_tokens  num_free  num_digits  \n",
       "0  0                   0         0           \n",
       "1  0                   0         0           \n",
       "2  2                   1         25          \n",
       "3  0                   0         0           \n",
       "4  0                   0         0           "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data['label'] = sms_data['spam'].map(lambda s: \"spam\" if s else \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data2 = sms_data[['length_chars','length_tokens', 'num_distinct_tokens', 'num_capital_chars', 'num_capital_tokens', 'num_free', 'num_digits', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll train a logistic regression classifier and evaluate it over the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make our splits.\n",
    "train_dev, test, train_dev_labels, test_labels = \\\n",
    "    train_test_split(sms_data2, sms_data2.label, test_size=0.30, stratify=sms_data2.label)\n",
    "train, dev, train_labels, dev_labels = \\\n",
    "    train_test_split(train_dev, train_dev_labels, test_size=0.30, stratify=train_dev_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in train.columns if x != 'label']\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(train[cols])\n",
    "train_scaled = train.copy()\n",
    "train_scaled[cols] = min_max_scaler.transform(train_scaled[cols])\n",
    "\n",
    "dev_scaled = train.copy()\n",
    "dev_scaled[cols] = min_max_scaler.transform(dev_scaled[cols])\n",
    "\n",
    "test_scaled = train.copy()\n",
    "test_scaled[cols] = min_max_scaler.transform(test_scaled[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "dev.to_csv(\"dev.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "train_scaled.to_csv(\"train_scaled.csv\", index=False)\n",
    "dev_scaled.to_csv(\"dev_scaled.csv\", index=False)\n",
    "test_scaled.to_csv(\"test_scaled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we evaluate the logistic regression model, here's the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8658119658119658\n",
      "AuROC: 0.5\n"
     ]
    }
   ],
   "source": [
    "baseline_predicted_labels = dev_labels * 0 ## All \"not-spam\".\n",
    "print(f'Accuracy: {metrics.accuracy_score(dev_labels, baseline_predicted_labels)}')\n",
    "print(f'AuROC: {metrics.roc_auc_score(dev_labels, baseline_predicted_labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the logistic regression model does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8957264957264958\n",
      "F1: 0.5378787878787878\n",
      "AuROC: 0.7083456467200283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('length_tokens', -0.7286595764365558),\n",
       " ('num_distinct_tokens', 0.6466058705291646),\n",
       " ('num_capital_tokens', -0.11943696628693701),\n",
       " ('num_capital_chars', 0.06349254714895461),\n",
       " ('length_chars', 0.051319354815039665)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Measure performance:\n",
    "print(f'Accuracy: {metrics.accuracy_score(dev_labels, predicted_labels)}')\n",
    "print(f'F1: {metrics.f1_score(dev_labels, predicted_labels)}')\n",
    "print(f'AuROC: {metrics.roc_auc_score(dev_labels, predicted_labels)}')\n",
    "\n",
    "\n",
    "## Feature weights.\n",
    "sorted(list(zip(train_features.columns, logistic.coef_[0])), key=lambda x: abs(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling\n",
    "\n",
    "Language models are distributions of tokens. For a collection of documents (think: a collection of SMS messages), we extract all of the tokens and for each distinct token we calculate the following numbers:\n",
    "\n",
    "  * how often does it occur in the collection\n",
    "  * in how many different documents does it occur\n",
    "\n",
    "Language models are useful in classification tasks such as spam filtering because we can model what spammy messages look like and model what non-spammy messages look like. Given a new message, we can calculate which model, spam or non-spam, the message seems more like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "NON_ALPHA = re.compile('\\W')\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return NON_ALPHA.sub(' ', text).lower().split()\n",
    "\n",
    "def buildModel(texts):\n",
    "    tfdict = {}\n",
    "    sum = 0\n",
    "        \n",
    "    for word in tokenize(' '.join(texts)):\n",
    "        if word not in tfdict:\n",
    "            tfdict[word] = 0\n",
    "            \n",
    "        tfdict[word] += 1\n",
    "        sum += 1\n",
    "            \n",
    "    return {'tf': tfdict, 'size': sum}\n",
    "\n",
    "def tf(token, documents, oov=0.05):\n",
    "    sum = 0\n",
    "    for document in documents:\n",
    "        if token in document['tf']:\n",
    "            sum = sum + document['tf'][token]\n",
    "            \n",
    "    return max(sum, oov)\n",
    "#     return max(oov, sum([document['tf'][token] for document in documents if token in document['tf']]))\n",
    "\n",
    "def queryLikelihood(query, documents, mu=None, oov=0.05):\n",
    "    queryTokens = tokenize(query)\n",
    "    collectionSize = sum([document['size'] for document in documents])*1.0\n",
    "    scores = []\n",
    "    if mu == None:\n",
    "        mu = collectionSize / len(documents)\n",
    "        \n",
    "    for i,D in enumerate(documents):\n",
    "        doc_score = 0\n",
    "        for q in queryTokens:\n",
    "            doc_score += math.log(\n",
    "                (tf(q, [D], oov) + (mu*tf(q, documents, oov)/collectionSize))) - math.log(\n",
    "                D['size'] + mu)\n",
    "        scores.append(doc_score)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def classifySMS(trainSMS, trainLabels, testSMS):\n",
    "    spamDocument = buildModel(trainSMS[trainLabels].tolist())\n",
    "    hamDocument = buildModel(trainSMS[trainLabels==False].tolist())\n",
    "    \n",
    "    def isSpam(sms):\n",
    "        scores = queryLikelihood(sms, [spamDocument, hamDocument], mu=20)\n",
    "        return scores[0] > scores[1]\n",
    "    \n",
    "    return testSMS.map(isSpam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = buildModel([\"Hello there! How are you?\"])\n",
    "doc2 = buildModel([\"I'm doing great, how are you?\"])\n",
    "#tf('how', [doc1, doc2])\n",
    "#queryLikelihood(\"I'm doing great\", [doc1, doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = classifySMS(train_sms['sms'], train_labels, dev_sms['sms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9700854700854701\n",
      "F1: 0.8973607038123168\n",
      "AuROC: 0.971960060613301\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {metrics.accuracy_score(dev_labels, predicted_labels)}')\n",
    "print(f'F1: {metrics.f1_score(dev_labels, predicted_labels)}')\n",
    "print(f'AuROC: {metrics.roc_auc_score(dev_labels, predicted_labels)}')\n",
    "\n",
    "\n",
    "## Feature weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
